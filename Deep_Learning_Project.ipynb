{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "DROPOUT = 0.4\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "MAX_TOKENS = 20000\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(\"amazon_reviews.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"=\"*50)\n",
        "    print(\"=\"*50)\n",
        "    df = pd.DataFrame(columns=[\"reviewText\", \"overall\"])\n",
        "\n",
        "if not df.empty:\n",
        "    df = df[[\"reviewText\", \"overall\"]].dropna()\n",
        "    df = df[df[\"overall\"] != 3]\n",
        "    df[\"label\"] = (df[\"overall\"] >= 4).astype(int)\n",
        "\n",
        "    pos_df = df[df[\"label\"] == 1]\n",
        "    neg_df = df[df[\"label\"] == 0]\n",
        "\n",
        "    neg_df_upsampled = resample(\n",
        "        neg_df,\n",
        "        replace=True,\n",
        "        n_samples=len(pos_df),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    df_balanced = pd.concat([pos_df, neg_df_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"Before upsampling:\")\n",
        "    print(df[\"label\"].value_counts())\n",
        "    print(\"\\nAfter upsampling:\")\n",
        "    print(df_balanced[\"label\"].value_counts())\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df_balanced[\"reviewText\"], df_balanced[\"label\"].values,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    vectorize_layer = layers.TextVectorization(\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        output_mode='int',\n",
        "        output_sequence_length=MAX_SEQUENCE_LENGTH\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"\\nAdapting TextVectorization layer...\")\n",
        "    vectorize_layer.adapt(train_texts)\n",
        "\n",
        "    VOCAB_SIZE = vectorize_layer.vocabulary_size()\n",
        "    print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
        "\n",
        "    def vectorize_text(text, label):\n",
        "        text = tf.expand_dims(text, -1)\n",
        "        return vectorize_layer(text), label\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((train_texts, train_labels))\n",
        "    train_ds = train_ds.batch(BATCH_SIZE).map(vectorize_text).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((test_texts, test_labels))\n",
        "    test_ds = test_ds.batch(BATCH_SIZE).map(vectorize_text).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    embedding_layer = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)\n",
        "\n",
        "    model = keras.Sequential([\n",
        "\n",
        "        layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int64\"),\n",
        "\n",
        "        embedding_layer,\n",
        "\n",
        "        layers.Dropout(DROPOUT),\n",
        "\n",
        "        layers.Bidirectional(\n",
        "            layers.LSTM(HIDDEN_DIM, return_sequences=True)\n",
        "        ),\n",
        "\n",
        "        layers.Dropout(DROPOUT),\n",
        "\n",
        "        layers.Bidirectional(\n",
        "            layers.LSTM(HIDDEN_DIM, return_sequences=False)\n",
        "        ),\n",
        "\n",
        "        layers.Dropout(DROPOUT),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            learning_rate=0.001,\n",
        "            clipnorm=5.0\n",
        "        ),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=test_ds\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Evaluating Model ---\")\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print(f\"\\n Test Accuracy (Balanced via Upsampling): {accuracy:.4f}\")\n",
        "\n",
        "    all_preds_prob = model.predict(test_ds)\n",
        "    all_preds = (all_preds_prob > 0.5).astype(int).squeeze()\n",
        "\n",
        "    all_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n",
        "\n",
        "    print(\"\\n Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"Negative\", \"Positive\"], digits=4))\n",
        "\n",
        "    print(\"\\n Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "    def predict_sentiment(text):\n",
        "        encoded_text = vectorize_layer([text])\n",
        "\n",
        "        prediction = model.predict(encoded_text, verbose=0)\n",
        "        pred_prob = prediction[0][0]\n",
        "\n",
        "        return \"Positive\" if pred_prob > 0.5 else \"Negative\"\n",
        "\n",
        "    positive_texts = [\n",
        "        \"I really love this product!\",\n",
        "        \"Absolutely fantastic, exceeded my expectations.\",\n",
        "        \"This is the best purchase I've made this year.\",\n",
        "        \"High quality and works perfectly.\",\n",
        "        \"I am very satisfied with this item.\",\n",
        "        \"Excellent product, would buy again.\",\n",
        "        \"Totally worth the money, highly recommend.\",\n",
        "        \"Amazing! Fast shipping and great quality.\",\n",
        "        \"Very happy with this, five stars!\",\n",
        "        \"This product is incredible, love it!\"\n",
        "    ]\n",
        "\n",
        "    negative_texts = [\n",
        "        \"Terrible quality, very disappointed.\",\n",
        "        \"Broke after one use, waste of money.\",\n",
        "        \"Do not buy this, completely useless.\",\n",
        "        \"Poorly made and arrived late.\",\n",
        "        \"Not as described, extremely unhappy.\",\n",
        "        \"This product is awful, avoid it.\",\n",
        "        \"Very disappointed, will never buy again.\",\n",
        "        \"Cheap material, doesn't work at all.\",\n",
        "        \"Horrible experience, one star.\",\n",
        "        \"Regret buying this, total waste.\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Positive Sentiment Predictions ---\")\n",
        "    for text in positive_texts:\n",
        "        sentiment = predict_sentiment(text)\n",
        "        print(f\"'{text}' -> {sentiment}\")\n",
        "\n",
        "    print(\"\\n--- Negative Sentiment Predictions ---\")\n",
        "    for text in negative_texts:\n",
        "        sentiment = predict_sentiment(text)\n",
        "        print(f\"'{text}' -> {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s5n6Em2bkTL8",
        "outputId": "8b9c959a-0f4f-4894-82ef-809bbf024377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before upsampling:\n",
            "label\n",
            "1    4448\n",
            "0     324\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After upsampling:\n",
            "label\n",
            "0    4448\n",
            "1    4448\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Adapting TextVectorization layer...\n",
            "Vocabulary size: 9719\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m2,488,064\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚     \u001b[38;5;34m3,149,824\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           â”‚     \u001b[38;5;34m6,295,552\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚         \u001b[38;5;34m1,025\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,488,064</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,149,824</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,295,552</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,934,465\u001b[0m (45.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,934,465</span> (45.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,934,465\u001b[0m (45.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,934,465</span> (45.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ğŸš€ Starting Training ---\n",
            "Epoch 1/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.8020 - loss: 0.4682 - val_accuracy: 0.9624 - val_loss: 0.1150\n",
            "Epoch 2/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 172ms/step - accuracy: 0.9707 - loss: 0.0904 - val_accuracy: 0.9685 - val_loss: 0.1166\n",
            "Epoch 3/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 173ms/step - accuracy: 0.9625 - loss: 0.1303 - val_accuracy: 0.9820 - val_loss: 0.0943\n",
            "Epoch 4/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9924 - loss: 0.0410 - val_accuracy: 0.9792 - val_loss: 0.0555\n",
            "Epoch 5/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 169ms/step - accuracy: 0.9930 - loss: 0.0286 - val_accuracy: 0.9871 - val_loss: 0.0364\n",
            "Epoch 6/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 169ms/step - accuracy: 0.9953 - loss: 0.0194 - val_accuracy: 0.9893 - val_loss: 0.0319\n",
            "Epoch 7/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 0.9803 - val_loss: 0.0870\n",
            "Epoch 8/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 172ms/step - accuracy: 0.9875 - loss: 0.0463 - val_accuracy: 0.9669 - val_loss: 0.1115\n",
            "Epoch 9/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9955 - loss: 0.0156 - val_accuracy: 0.9871 - val_loss: 0.0452\n",
            "Epoch 10/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 171ms/step - accuracy: 0.9989 - loss: 0.0067 - val_accuracy: 0.9933 - val_loss: 0.0350\n",
            "\n",
            "--- ğŸ“Š Evaluating Model ---\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9924 - loss: 0.0391\n",
            "\n",
            "âœ… Test Accuracy (Balanced via Upsampling): 0.9933\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step\n",
            "\n",
            "ğŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative     0.9865    1.0000    0.9932       878\n",
            "    Positive     1.0000    0.9867    0.9933       902\n",
            "\n",
            "    accuracy                         0.9933      1780\n",
            "   macro avg     0.9933    0.9933    0.9933      1780\n",
            "weighted avg     0.9933    0.9933    0.9933      1780\n",
            "\n",
            "\n",
            "ğŸ§¾ Confusion Matrix:\n",
            "[[878   0]\n",
            " [ 12 890]]\n",
            "\n",
            "--- Positive Sentiment Predictions ---\n",
            "'I really love this product!' -> Positive\n",
            "'Absolutely fantastic, exceeded my expectations.' -> Positive\n",
            "'This is the best purchase I've made this year.' -> Positive\n",
            "'High quality and works perfectly.' -> Positive\n",
            "'I am very satisfied with this item.' -> Positive\n",
            "'Excellent product, would buy again.' -> Positive\n",
            "'Totally worth the money, highly recommend.' -> Positive\n",
            "'Amazing! Fast shipping and great quality.' -> Positive\n",
            "'Very happy with this, five stars!' -> Positive\n",
            "'This product is incredible, love it!' -> Positive\n",
            "\n",
            "--- Negative Sentiment Predictions ---\n",
            "'Terrible quality, very disappointed.' -> Negative\n",
            "'Broke after one use, waste of money.' -> Negative\n",
            "'Do not buy this, completely useless.' -> Negative\n",
            "'Poorly made and arrived late.' -> Positive\n",
            "'Not as described, extremely unhappy.' -> Positive\n",
            "'This product is awful, avoid it.' -> Negative\n",
            "'Very disappointed, will never buy again.' -> Negative\n",
            "'Cheap material, doesn't work at all.' -> Positive\n",
            "'Horrible experience, one star.' -> Positive\n",
            "'Regret buying this, total waste.' -> Negative\n"
          ]
        }
      ]
    }
  ]
}